{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import ast\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utilities import logger\n",
    "from utilities import configuration\n",
    "from utilities import health_data\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'fix_skew': True,\n",
    "          'normalize': True,\n",
    "          'fix_missing_in_testing': True,\n",
    "          'numerical_features': True,\n",
    "          'categorical_features': True,\n",
    "          'diagnosis_features': True,\n",
    "          'intervention_features':True,\n",
    "          'use_idf':True,\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances before filtering: 419988\n",
      "Training instances after filtering:  419988\n",
      "Testomg instances before filtering:  104998\n",
      "Testomg instances after filtering:   104998\n",
      "Training size: 419,988\n",
      "Testing size:  104,998\n"
     ]
    }
   ],
   "source": [
    "training ,testing = health_data.Admission.get_training_testing_data()\n",
    "    \n",
    "if params['fix_missing_in_testing']:\n",
    "    for admission in testing:\n",
    "        admission.fix_missings(training)\n",
    "\n",
    "print(f'Training size: {len(training):,}')\n",
    "print(f'Testing size:  {len(testing):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (419,345 x 17,083)\n",
      "y_train.shape = (419,345 x )\n",
      "\n",
      "X_test.shape =  (104,884 x 17,083)\n",
      "y_test.shape =  (104,884 x )\n"
     ]
    }
   ],
   "source": [
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# Training \n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "features = []\n",
    "if params['numerical_features']:\n",
    "    numerical_df = health_data.Admission.numerical_features(training, \n",
    "                                                            fix_skew=params['fix_skew'], \n",
    "                                                            normalize=params['normalize'])\n",
    "    features.append(sparse.csr_matrix(numerical_df.values))\n",
    "\n",
    "if params['categorical_features']:\n",
    "    categorical_df,main_pt_services_list = health_data.Admission.categorical_features(training)\n",
    "    features.append(sparse.csr_matrix(categorical_df.values))\n",
    "\n",
    "if params['diagnosis_features']:\n",
    "    vocab_diagnosis, diagnosis_matrix = health_data.Admission.diagnosis_codes_features(training, \n",
    "                                                                                       use_idf=params['use_idf'])\n",
    "    features.append(diagnosis_matrix)\n",
    "\n",
    "if params['intervention_features']:\n",
    "    vocab_interventions, intervention_matrix = health_data.Admission.intervention_codes_features(training, \n",
    "                                                                                                 use_idf=params['use_idf'])\n",
    "    features.append(intervention_matrix)\n",
    "\n",
    "X_train = sparse.hstack(features)\n",
    "y_train = health_data.Admission.get_y(training)\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# Testing\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "features = []\n",
    "if params['numerical_features']:\n",
    "    numerical_df = health_data.Admission.numerical_features(testing, \n",
    "                                                            fix_skew=params['fix_skew'], \n",
    "                                                            normalize=params['normalize'])\n",
    "    features.append(sparse.csr_matrix(numerical_df.values))\n",
    "\n",
    "if params['categorical_features']:\n",
    "    categorical_df, _ = health_data.Admission.categorical_features(testing, main_pt_services_list=main_pt_services_list)\n",
    "    features.append(sparse.csr_matrix(categorical_df.values))\n",
    "\n",
    "if params['diagnosis_features']:\n",
    "    vocab_diagnosis, diagnosis_matrix = health_data.Admission.diagnosis_codes_features(testing, \n",
    "                                                                                       vocabulary=vocab_diagnosis, \n",
    "                                                                                       use_idf=params['use_idf'])\n",
    "    features.append(diagnosis_matrix)\n",
    "\n",
    "if params['intervention_features']:\n",
    "    vocab_interventions, intervention_matrix = health_data.Admission.intervention_codes_features(testing, \n",
    "                                                                                                 vocabulary=vocab_interventions, \n",
    "                                                                                                 use_idf=params['use_idf']\n",
    "                                                                                                 )\n",
    "    features.append(intervention_matrix)\n",
    "\n",
    "# numerical_df = health_data.Admission.numerical_features(testing, fix_skew=params['fix_skew'], normalize=params['normalize'])\n",
    "# categorical_df = health_data.Admission.categorical_features(testing)\n",
    "# vocab_diagnosis, diagnosis_matrix = health_data.Admission.diagnosis_codes_features(testing, \n",
    "#                                                                                    vocabulary=vocab_diagnosis)\n",
    "# vocab_interventions, intervention_matrix = health_data.Admission.intervention_codes_features(testing, \n",
    "#                                                                                              vocabulary=vocab_interventions)\n",
    "\n",
    "X_test = sparse.hstack(features)\n",
    "y_test = health_data.Admission.get_y(testing)\n",
    "\n",
    "\n",
    "print(f'X_train.shape = ({X_train.shape[0]:,} x {X_train.shape[1]:,})')\n",
    "print(f'y_train.shape = ({y_train.shape[0]:,} x )')\n",
    "print()\n",
    "print(f'X_test.shape =  ({X_test.shape[0]:,} x {X_test.shape[1]:,})')\n",
    "print(f'y_test.shape =  ({y_test.shape[0]:,} x )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model;params;split;TN;FP;FN;TP;Precision;Recall;F1-Score;AUC\n",
      "LogisticRegression(class_weight='balanced', max_iter=7000);{'fix_skew': True, 'normalize': True, 'fix_missing_in_testing': True, 'numerical_features': True, 'categorical_features': True, 'diagnosis_features': True, 'intervention_features': True, 'use_idf': True};train;269812;132121;4050;13362;0.09184578266876542;0.7674017918676774;0.16405660087786608;0.7193439011113185\n",
      "LogisticRegression(class_weight='balanced', max_iter=7000);{'fix_skew': True, 'normalize': True, 'fix_missing_in_testing': True, 'numerical_features': True, 'categorical_features': True, 'diagnosis_features': True, 'intervention_features': True, 'use_idf': True};test;66793;33558;1744;2789;0.07673260516686384;0.6152658283697331;0.1364481409001957;0.6404297971257441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', max_iter=7000,).fit(X_train, y_train,)\n",
    "\n",
    "y_true = y_train\n",
    "y_pred = clf.predict(X_train)\n",
    "y_score= clf.predict_proba(X_train)\n",
    "\n",
    "model_name = str(clf)\n",
    "columns = ['Model','params','split','TN','FP','FN','TP','Precision','Recall','F1-Score','AUC']\n",
    "str_ = ';'.join(columns)\n",
    "logging.debug(str_)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "str_ = f'{model_name};{str(params)};train;{tn};{fp};{fn};{tp};{precision_score(y_true, y_pred,)};{recall_score(y_true, y_pred,)};'\\\n",
    "    f'{f1_score(y_true, y_pred,)};{roc_auc_score(y_true=y_true, y_score=y_pred)}\\n'\n",
    "logging.debug(str_)\n",
    "\n",
    "\n",
    "vec1 = [model_name,\n",
    "        str(params),\n",
    "        'TRAIN',\n",
    "        tn,\n",
    "        fp,\n",
    "        fn,\n",
    "        tp,\n",
    "        precision_score(y_true, y_pred,),\n",
    "        recall_score(y_true, y_pred,),\n",
    "        f1_score(y_true, y_pred,),\n",
    "        roc_auc_score(y_true=y_true, y_score=y_pred),\n",
    "        ]\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score= clf.predict_proba(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "str_ = f'{model_name};{str(params)};test;{tn};{fp};{fn};{tp};{precision_score(y_true, y_pred,)};{recall_score(y_true, y_pred,)};'\\\n",
    "    f'{f1_score(y_true, y_pred,):};{roc_auc_score(y_true=y_true, y_score=y_pred)}\\n'\n",
    "\n",
    "vec2 = [model_name,\n",
    "        str(params),\n",
    "        'TEST',\n",
    "        tn,\n",
    "        fp,\n",
    "        fn,\n",
    "        tp,\n",
    "        precision_score(y_true, y_pred,),\n",
    "        recall_score(y_true, y_pred,),\n",
    "        f1_score(y_true, y_pred,),\n",
    "        roc_auc_score(y_true=y_true, y_score=y_pred),\n",
    "        ]\n",
    "\n",
    "\n",
    "logging.debug(str_)\n",
    "\n",
    "# print('** Results on Training **')\n",
    "# print('     ~Real values~')\n",
    "# print(f'         0       1')\n",
    "# print(f'0: {tn:7,} {fn:7,}')\n",
    "# print(f'1: {fp:7,} {tp:7,}')\n",
    "# print()\n",
    "\n",
    "# print(f'Precision= {precision_score(y_true, y_pred,):7.4f}')\n",
    "# print(f'Recall=    {recall_score(y_true, y_pred,):7.4f}')\n",
    "# print(f'F1-score=  {f1_score(y_true, y_pred,):7.4f}')\n",
    "# print(f'AUC=       {roc_auc_score(y_true=y_true, y_score=y_pred):7.4f}')\n",
    "# print()\n",
    "\n",
    "\n",
    "# print('** Results on Testing **')\n",
    "# print('     ~Real values~')\n",
    "# print(f'         0       1')\n",
    "# print(f'0: {tn:7,} {fn:7,}')\n",
    "# print(f'1: {fp:7,} {tp:7,}')\n",
    "# print()\n",
    "\n",
    "\n",
    "# print(f'Precision= {precision_score(y_true, y_pred,):7.4f}')\n",
    "# print(f'Recall=    {recall_score(y_true, y_pred,):7.4f}')\n",
    "# print(f'F1-score=  {f1_score(y_true, y_pred,):7.4f}')\n",
    "# print(f'AUC=       {roc_auc_score(y_true=y_true, y_score=y_pred):7.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "0.0055%\n"
     ]
    }
   ],
   "source": [
    "# training ,testing = health_data.Admission.get_training_testing_data()\n",
    "# if params['fix_missing_in_testing']:\n",
    "#     for admission in testing:\n",
    "#         admission.fix_missings(training)\n",
    "\n",
    "missing_count=0\n",
    "for admission in testing:\n",
    "    if admission.case_weight is None or np.isnan(admission.case_weight):\n",
    "        missing_count+=1\n",
    "print(missing_count)\n",
    "print(f'{missing_count/len(training):.4%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([admission.main_pt_service for admission in training]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transfusion given</th>\n",
       "      <th>is alc</th>\n",
       "      <th>is central zone</th>\n",
       "      <th>elective admission</th>\n",
       "      <th>new born admission</th>\n",
       "      <th>urgent admission</th>\n",
       "      <th>level 1 comorbidity</th>\n",
       "      <th>level 2 comorbidity</th>\n",
       "      <th>...</th>\n",
       "      <th>General Medicine</th>\n",
       "      <th>Paediatric Medicine</th>\n",
       "      <th>Neurology</th>\n",
       "      <th>OBS Aborted</th>\n",
       "      <th>Cardiovascular Surgery</th>\n",
       "      <th>Haematology</th>\n",
       "      <th>Otolaryngology and ORL</th>\n",
       "      <th>Allergy</th>\n",
       "      <th>Genetics</th>\n",
       "      <th>OBS Delivered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419134</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419135</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419136</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419137</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419138</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419139 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        male  female  transfusion given  is alc  is central zone  \\\n",
       "0          0       1                  0       0                1   \n",
       "1          1       0                  0       0                1   \n",
       "2          0       1                  0       0                1   \n",
       "3          0       1                  0       0                1   \n",
       "4          0       1                  0       0                1   \n",
       "...      ...     ...                ...     ...              ...   \n",
       "419134     1       0                  0       0                0   \n",
       "419135     1       0                  0       0                0   \n",
       "419136     1       0                  0       0                0   \n",
       "419137     0       1                  0       0                0   \n",
       "419138     1       0                  0       0                0   \n",
       "\n",
       "        elective admission  new born admission  urgent admission  \\\n",
       "0                        0                   0                 1   \n",
       "1                        1                   0                 0   \n",
       "2                        0                   0                 1   \n",
       "3                        0                   0                 1   \n",
       "4                        0                   0                 1   \n",
       "...                    ...                 ...               ...   \n",
       "419134                   0                   0                 1   \n",
       "419135                   0                   0                 1   \n",
       "419136                   0                   0                 1   \n",
       "419137                   1                   0                 0   \n",
       "419138                   0                   0                 1   \n",
       "\n",
       "        level 1 comorbidity  level 2 comorbidity  ...  General Medicine  \\\n",
       "0                         0                    0  ...                 0   \n",
       "1                         0                    0  ...                 0   \n",
       "2                         1                    0  ...                 0   \n",
       "3                         0                    0  ...                 0   \n",
       "4                         0                    0  ...                 0   \n",
       "...                     ...                  ...  ...               ...   \n",
       "419134                    1                    1  ...                 0   \n",
       "419135                    0                    0  ...                 0   \n",
       "419136                    1                    0  ...                 1   \n",
       "419137                    0                    0  ...                 0   \n",
       "419138                    1                    1  ...                 1   \n",
       "\n",
       "        Paediatric Medicine  Neurology  OBS Aborted  Cardiovascular Surgery  \\\n",
       "0                         0          0            0                       0   \n",
       "1                         0          0            0                       0   \n",
       "2                         0          0            0                       0   \n",
       "3                         0          0            0                       0   \n",
       "4                         0          0            0                       0   \n",
       "...                     ...        ...          ...                     ...   \n",
       "419134                    0          0            0                       0   \n",
       "419135                    0          0            0                       0   \n",
       "419136                    0          0            0                       0   \n",
       "419137                    0          0            0                       0   \n",
       "419138                    0          0            0                       0   \n",
       "\n",
       "        Haematology  Otolaryngology and ORL  Allergy  Genetics  OBS Delivered  \n",
       "0                 0                       0        0         0              0  \n",
       "1                 0                       0        0         0              0  \n",
       "2                 0                       0        0         0              0  \n",
       "3                 0                       0        0         0              0  \n",
       "4                 0                       0        0         0              0  \n",
       "...             ...                     ...      ...       ...            ...  \n",
       "419134            0                       0        0         0              0  \n",
       "419135            0                       0        0         0              0  \n",
       "419136            0                       0        0         0              0  \n",
       "419137            0                       0        0         0              0  \n",
       "419138            0                       0        0         0              0  \n",
       "\n",
       "[419139 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_df,_ = health_data.Admission.categorical_features(training)\n",
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                   1\n",
       "is central zone        1\n",
       "urgent admission       1\n",
       "level 1 comorbidity    1\n",
       "level 2 comorbidity    1\n",
       "Family Practice        1\n",
       "Name: 8, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_df.iloc[instance_no,:][categorical_df.iloc[instance_no,:]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, df = health_data.Admission.intervention_codes_features(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B2N7H9', 1), ('B0E3P0', 1)]\n",
      "[('B0K1H0', 5104), ('B0P1R0', 5232)]\n"
     ]
    }
   ],
   "source": [
    "freq = defaultdict(int)\n",
    "for admission in training+testing:\n",
    "    freq[admission.postal_code]+=1\n",
    "\n",
    "zip_codes = [(key,value) for key,value in freq.items()]\n",
    "sorted_zip_codes = sorted(zip_codes, key=lambda key_value: key_value[1])\n",
    "print(sorted_zip_codes[:2])\n",
    "print(sorted_zip_codes[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000%\n"
     ]
    }
   ],
   "source": [
    "field = 'diagnosis'\n",
    "missing = len([_ for admission in training+testing if getattr(admission,field).codes is None])\n",
    "print(f'{missing/len(training+testing):.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
