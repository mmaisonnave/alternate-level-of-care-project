{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import ast\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utilities import logger\n",
    "from utilities import configuration\n",
    "from utilities import health_data\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_log                               (type: <class 'str'>)\n",
      "json_file                                (type: <class 'str'>)\n",
      "train_val_json                           (type: <class 'str'>)\n",
      "heldout_json                             (type: <class 'str'>)\n",
      "unified_merged_file_cz                   (type: <class 'str'>)\n",
      "unified_merged_file_noncz                (type: <class 'str'>)\n",
      "unified_merged_file                      (type: <class 'str'>)\n",
      "data_path                                (type: <class 'str'>)\n",
      "cz_files                                 (type: <class 'list'>)\n",
      "noncz_files                              (type: <class 'list'>)\n",
      "2023-11-07 18:47:40,558 - root - DEBUG - Logger has started ont notebook 09 Random sample of instances.ipynb ...\n"
     ]
    }
   ],
   "source": [
    "config = configuration.get_config()\n",
    "for key in config:\n",
    "    print(f'{key:40} (type: {type(config[key])})')\n",
    "\n",
    "\n",
    "logging = logger.init_logger(config['system_log'])\n",
    "logging.debug('Logger has started ont notebook 09 Random sample of instances.ipynb ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524986\n",
      "263719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50533"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(config['train_val_json'])\n",
    "train_val_data = json.load(f)\n",
    "print(len(train_val_data))\n",
    "\n",
    "all_admissions = []\n",
    "for ix in train_val_data:\n",
    "    all_admissions.append(\n",
    "        health_data.Admission.from_dict_data(admit_id=int(ix), admission=train_val_data[ix])\n",
    "        )\n",
    "len(all_admissions)\n",
    "\n",
    "\n",
    "# Dictionary organizing data by patient\n",
    "patient2admissions = defaultdict(list)\n",
    "for admission in all_admissions:\n",
    "    code = admission.code\n",
    "    patient2admissions[code].append(admission)\n",
    "\n",
    "# Ordering patient list by discharge date (from back )\n",
    "for patient_code in patient2admissions:\n",
    "    admissions_list = patient2admissions[patient_code]\n",
    "    admissions_list = sorted(admissions_list, key=lambda admission: admission.discharge_date, reverse=False)\n",
    "    assert all([admissions_list[i].discharge_date <= admissions_list[i+1].discharge_date for i in range(len(admissions_list)-1)])\n",
    "    patient2admissions[patient_code] = admissions_list\n",
    "print(len(patient2admissions))\n",
    "\n",
    "patient_count=0\n",
    "valid_readmission_count=0\n",
    "for patient_code in patient2admissions:\n",
    "    patient_admissions = patient2admissions[patient_code]\n",
    "    ix = 0 \n",
    "    while ix < len(patient_admissions):\n",
    "        readmission_code = patient_admissions[ix].readmission_code\n",
    "        if health_data.ReadmissionCode.is_readmit(readmission_code):\n",
    "            # Either is not the first admission (ix>0) or \n",
    "            # we don't have the patient previous admition (readmission close to begining of dataset) (admit-(2015-01-01))<28 days\n",
    "            # assert ix>0 or (patient_admissions[ix].admit_date - datetime.datetime.fromisoformat('2015-01-01')).days<365\n",
    "            if ix>0 and  patient_admissions[ix-1].is_valid_readmission(patient_admissions[ix]):\n",
    "                patient_admissions[ix-1].add_readmission(patient_admissions[ix])\n",
    "                valid_readmission_count+=1\n",
    "        ix+=1\n",
    "    patient_count+=1\n",
    "valid_readmission_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features=9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9929"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9945\n"
     ]
    }
   ],
   "source": [
    "# freq = defaultdict(int)\n",
    "# for admission in all_admissions:\n",
    "#     for code in admission.diagnosis.codes:\n",
    "#         freq[code]+=1\n",
    "# print(len(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aaa', 'aaab', 'bs'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# type(vectorizer.fit_transform(['aaa aaab', 'aaa bs']))\n",
    "# vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9929 distincts codes.\n",
      "After filtering codes that appear 0 times or less we have 9929 codes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9929,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from scipy.sparse._csr import csr_matrix\n",
    "\n",
    "# def create_codes_matrix(admissions: list[health_data.Admission], freq_cutoff=0)->pd.DataFrame:\n",
    "#     freq = defaultdict(int)\n",
    "#     for admission in admissions:\n",
    "#         for code in admission.diagnosis.codes:\n",
    "#             freq[code.lower()]+=1\n",
    "#     print(f'Found {len(freq)} distincts codes.')\n",
    "#     codes_vocab = np.array([code for code in freq if freq[code]>freq_cutoff])\n",
    "#     print(f'After filtering codes that appear {freq_cutoff} times or less we have {len(codes_vocab)} codes.')\n",
    "\n",
    "\n",
    "#     return codes_vocab, matrix\n",
    "\n",
    "# codes_vocab, matrix = create_codes_matrix(all_admissions)\n",
    "# codes_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features=9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9929,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from scipy.sparse._csr import csr_matrix\n",
    "\n",
    "\n",
    "#     # freq = defaultdict(int)\n",
    "#     # for admission in admissions:\n",
    "#     #     for code in admission.diagnosis.codes:\n",
    "#     #         freq[code]+=1\n",
    "#     # print(f'Found {len(freq)} distincts codes.')\n",
    "#     # codes_vocab = np.array([code for code in freq if freq[code]>freq_cutoff])\n",
    "#     # print(f'After filtering codes that appear {freq_cutoff} times or less we have {len(codes_vocab)} codes.')\n",
    "#     # code2index = dict([(code, idx) for idx,code in enumerate(codes_vocab)])\n",
    "#     # del(freq)\n",
    "\n",
    "#     # matrix = csr_matrix((len(admissions),len(codes_vocab)), dtype=np.int8)\n",
    "#     # for ix, admission in enumerate(admissions):\n",
    "#     #     for code in admission.diagnosis.codes:\n",
    "#     #         if code in code2index:\n",
    "#     #             matrix[ix, code2index[code]] += 1\n",
    "\n",
    "#     return codes_vocab, matrix\n",
    "\n",
    "\n",
    "# codes_vocab2, matrix = create_codes_matrix(all_admissions)\n",
    "# codes_vocab2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(codes_vocab)==set(codes_vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<524986x8397 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2314704 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(seed=5348363479653547918)\n",
    "\n",
    "# train_indexes = rng.choice(range(len(all_admissions)),size=int(0.8*len(all_admissions)), replace=False)\n",
    "\n",
    "# # Checking that every time I am getting the same training instances ( and validation instances)\n",
    "# assert all(train_indexes[:3] ==np.array([478898, 46409, 322969]))\n",
    "# assert all(train_indexes[-3:] ==np.array([415014, 330673, 338415]))\n",
    "# assert hash(tuple(train_indexes))==2028319680436964623\n",
    "\n",
    "# train_indexes = set(train_indexes)\n",
    "\n",
    "# train = [admission for ix, admission in enumerate(all_admissions) if ix in train_indexes ]\n",
    "# validation = [admission for ix, admission in enumerate(all_admissions) if not ix in train_indexes ]\n",
    "\n",
    "# print(f'Size of training (before filter)=     {len(train):,}')\n",
    "# print(f'Size of validation (before filter)=   {len(validation):,}')\n",
    "\n",
    "# # Filtering missing values\n",
    "# train = list(filter(lambda admission: not admission.has_missing, train))\n",
    "# validation = list(filter(lambda admission: not admission.has_missing, validation))\n",
    "\n",
    "\n",
    "# # Filtering STILL_BORNS admissions\n",
    "# train = list(filter(lambda admission: admission.admit_category!=health_data.AdmitCategory.STILLBORN, train))\n",
    "# validation = list(filter(lambda admission: admission.admit_category!=health_data.AdmitCategory.STILLBORN, validation))\n",
    "\n",
    "# # Filtering CADAVER admissions\n",
    "# train = list(filter(lambda admission: admission.admit_category!=health_data.AdmitCategory.CADAVER, train))\n",
    "# validation = list(filter(lambda admission: admission.admit_category!=health_data.AdmitCategory.CADAVER, validation))\n",
    "\n",
    "\n",
    "# print(f'Size of training (after filter)=      {len(train):,}')\n",
    "# print(f'Size of validation (after filter)=    {len(validation):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features=9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianomaisonnave/Environments/alc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "vocab, matrix = health_data.Admission.create_codes_matrix(all_admissions)\n",
    "\n",
    "X = matrix\n",
    "y = health_data.Admission.get_y(all_admissions)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
