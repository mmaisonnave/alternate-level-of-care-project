{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 09:25:11,353 - root - DEBUG - Starting LASSO experiments ...\n",
      "2023-11-22 09:25:11,363 - root - DEBUG - fix_skew                      =False\n",
      "2023-11-22 09:25:11,367 - root - DEBUG - normalize                     =False\n",
      "2023-11-22 09:25:11,369 - root - DEBUG - fix_missing_in_testing        =True\n",
      "2023-11-22 09:25:11,372 - root - DEBUG - numerical_features            =True\n",
      "2023-11-22 09:25:11,376 - root - DEBUG - categorical_features          =True\n",
      "2023-11-22 09:25:11,377 - root - DEBUG - diagnosis_features            =True\n",
      "2023-11-22 09:25:11,377 - root - DEBUG - intervention_features         =True\n",
      "2023-11-22 09:25:11,378 - root - DEBUG - use_idf                       =False\n",
      "2023-11-22 09:25:11,378 - root - DEBUG - remove_outliers               =False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances before filtering: 419988\n",
      "Training instances after filtering:  419139\n",
      "Testomg instances before filtering:  104998\n",
      "Testomg instances after filtering:   104884\n",
      "2023-11-22 09:25:46,723 - root - DEBUG - Training size=419,139\n",
      "2023-11-22 09:25:46,724 - root - DEBUG - Testing  size=104,884\n",
      "2023-11-22 09:26:06,935 - root - DEBUG - X_train.shape = (419,139 x 17,129)\n",
      "2023-11-22 09:26:06,936 - root - DEBUG - y_train.shape = (419,139 x )\n",
      "2023-11-22 09:26:06,937 - root - DEBUG - X_test.shape =  (104,884 x 17,129)\n",
      "2023-11-22 09:26:06,937 - root - DEBUG - y_test.shape =  (104,884 x )\n",
      "2023-11-22 09:26:30,946 - root - DEBUG - Model;params;split;TN;FP;FN;TP;Precision;Recall;F1-Score;AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianomaisonnave/Environments/alc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 09:26:31,361 - root - DEBUG - Lasso(max_iter=7000);{'fix_skew': False, 'normalize': False, 'fix_missing_in_testing': True, 'numerical_features': True, 'categorical_features': True, 'diagnosis_features': True, 'intervention_features': True, 'use_idf': False, 'remove_outliers': False};TRAIN;401737;0;17402;0;0.0;0.0;0.0;0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianomaisonnave/Environments/alc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 09:26:31,834 - root - DEBUG - Lasso(max_iter=7000);{'fix_skew': False, 'normalize': False, 'fix_missing_in_testing': True, 'numerical_features': True, 'categorical_features': True, 'diagnosis_features': True, 'intervention_features': True, 'use_idf': False, 'remove_outliers': False};TEST;100351;0;4533;0;0.0;0.0;0.0;0.5\n",
      "2023-11-22 09:26:31,927 - root - DEBUG - Finishing Logistic Regression execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianomaisonnave/Environments/alc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/marianomaisonnave/Environments/alc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utilities import logger\n",
    "from utilities import configuration\n",
    "from utilities import health_data\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import f1_score, precision_score,recall_score,roc_auc_score,confusion_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# LOGGING\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "config = configuration.get_config()\n",
    "logging = logger.init_logger(config['lasso_log'])\n",
    "logging.debug('Starting LASSO experiments ...')\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# MANAGING ARGUMENTS\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "numerical_features = True\n",
    "categorical_features = True \n",
    "diagnosis_features = True \n",
    "intervention_features = True \n",
    "\n",
    "fix_missings = True\n",
    "normalize = False\n",
    "fix_skew = False\n",
    "use_idf = False\n",
    "# class_balanced = True\n",
    "remove_outliers = False\n",
    "\n",
    "params = {'fix_skew': fix_skew,\n",
    "            'normalize': normalize,\n",
    "            'fix_missing_in_testing': fix_missings,\n",
    "            'numerical_features': numerical_features,\n",
    "            'categorical_features': categorical_features,\n",
    "            'diagnosis_features': diagnosis_features,\n",
    "            'intervention_features':intervention_features,\n",
    "            'use_idf':use_idf,\n",
    "            # 'class_balanced':class_balanced,\n",
    "            'remove_outliers': remove_outliers,\n",
    "        }\n",
    "\n",
    "for key, value in params.items():\n",
    "    logging.debug(f'{key:30}={value}')\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# RETRIEVING TRAIN AND TEST\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "training ,testing = health_data.Admission.get_training_testing_data()\n",
    "if params['fix_missing_in_testing']:\n",
    "    for admission in testing:\n",
    "        admission.fix_missings(training)\n",
    "        \n",
    "logging.debug(f'Training size={len(training):,}')\n",
    "logging.debug(f'Testing  size={len(testing):,}')\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# TRAINING MATRIX\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "features = []\n",
    "if params['numerical_features']:\n",
    "    numerical_df = health_data.Admission.numerical_features(training, \n",
    "                                                            fix_skew=params['fix_skew'], \n",
    "                                                            normalize=params['normalize'])\n",
    "    if params['remove_outliers']:\n",
    "        stds = np.std(numerical_df)\n",
    "        mean = np.mean(numerical_df, axis=0)\n",
    "        is_outlier=np.sum(numerical_df.values > (mean*4*stds).values, axis=1)>0\n",
    "\n",
    "    features.append(sparse.csr_matrix(numerical_df.values))\n",
    "\n",
    "if params['categorical_features']:\n",
    "    categorical_df, main_pt_services_list = health_data.Admission.categorical_features(training)\n",
    "    features.append(sparse.csr_matrix(categorical_df.values))\n",
    "\n",
    "if params['diagnosis_features']:\n",
    "    vocab_diagnosis, diagnosis_matrix = health_data.Admission.diagnosis_codes_features(training, \n",
    "                                                                                    use_idf=params['use_idf'])\n",
    "    features.append(diagnosis_matrix)\n",
    "\n",
    "if params['intervention_features']:\n",
    "    vocab_interventions, intervention_matrix = health_data.Admission.intervention_codes_features(training, \n",
    "                                                                                                use_idf=params['use_idf'])\n",
    "    features.append(intervention_matrix)\n",
    "\n",
    "if params['remove_outliers']:\n",
    "    mask=~is_outlier\n",
    "else:\n",
    "    mask = np.ones(shape=(len(training)))==1\n",
    "\n",
    "X_train = sparse.hstack([matrix[mask,:] for matrix in features])\n",
    "y_train = health_data.Admission.get_y(training)[mask]\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# TESTING MATRIX\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "features = []\n",
    "if params['numerical_features']:\n",
    "    numerical_df = health_data.Admission.numerical_features(testing, \n",
    "                                                            fix_skew=params['fix_skew'], \n",
    "                                                            normalize=params['normalize'])\n",
    "    features.append(sparse.csr_matrix(numerical_df.values))\n",
    "\n",
    "if params['categorical_features']:\n",
    "    categorical_df,_ = health_data.Admission.categorical_features(testing, main_pt_services_list=main_pt_services_list)\n",
    "    features.append(sparse.csr_matrix(categorical_df.values))\n",
    "\n",
    "if params['diagnosis_features']:\n",
    "    vocab_diagnosis, diagnosis_matrix = health_data.Admission.diagnosis_codes_features(testing, \n",
    "                                                                                    vocabulary=vocab_diagnosis, \n",
    "                                                                                    use_idf=params['use_idf'])\n",
    "    features.append(diagnosis_matrix)\n",
    "\n",
    "if params['intervention_features']:\n",
    "    vocab_interventions, intervention_matrix = health_data.Admission.intervention_codes_features(testing, \n",
    "                                                                                                vocabulary=vocab_interventions, \n",
    "                                                                                                use_idf=params['use_idf']\n",
    "                                                                                                )\n",
    "    features.append(intervention_matrix)\n",
    "\n",
    "X_test = sparse.hstack(features)\n",
    "y_test = health_data.Admission.get_y(testing)\n",
    "\n",
    "\n",
    "logging.debug(f'X_train.shape = ({X_train.shape[0]:,} x {X_train.shape[1]:,})')\n",
    "logging.debug(f'y_train.shape = ({y_train.shape[0]:,} x )')\n",
    "# print()\n",
    "logging.debug(f'X_test.shape =  ({X_test.shape[0]:,} x {X_test.shape[1]:,})')\n",
    "logging.debug(f'y_test.shape =  ({y_test.shape[0]:,} x )')\n",
    "\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ----------\n",
    "# LOGISTIC REGRESSION MODEL \n",
    "# ---------- ---------- ---------- ---------- ---------- ---------- ---------- ---------- \n",
    "# class_weight = 'balanced' if params['class_balanced'] else None\n",
    "clf = Lasso(max_iter=7000,).fit(X_train, y_train,)\n",
    "\n",
    "y_true = y_train\n",
    "y_pred = clf.predict(X_train) > 0.5\n",
    "y_score= clf.predict(X_train)\n",
    "\n",
    "model_name = str(clf)\n",
    "columns = ['Model','params','split','TN','FP','FN','TP','Precision','Recall','F1-Score','AUC']\n",
    "str_ = ';'.join(columns)\n",
    "logging.debug(str_)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "str_ = f'{model_name};{str(params)};TRAIN;{tn};{fp};{fn};{tp};{precision_score(y_true, y_pred,)};{recall_score(y_true, y_pred,)};'\\\n",
    "    f'{f1_score(y_true, y_pred,)};{roc_auc_score(y_true=y_true, y_score=y_pred)}'\n",
    "logging.debug(str_)\n",
    "\n",
    "\n",
    "vec1 = [model_name,\n",
    "        str(params),\n",
    "        'TRAIN',\n",
    "        tn,\n",
    "        fp,\n",
    "        fn,\n",
    "        tp,\n",
    "        precision_score(y_true, y_pred,),\n",
    "        recall_score(y_true, y_pred,),\n",
    "        f1_score(y_true, y_pred,),\n",
    "        roc_auc_score(y_true=y_true, y_score=y_pred),\n",
    "        ]\n",
    "\n",
    "y_true = y_test \n",
    "y_pred = clf.predict(X_test) > 0.5\n",
    "y_score= clf.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "str_ = f'{model_name};{str(params)};TEST;{tn};{fp};{fn};{tp};{precision_score(y_true, y_pred,)};{recall_score(y_true, y_pred,)};'\\\n",
    "    f'{f1_score(y_true, y_pred,):};{roc_auc_score(y_true=y_true, y_score=y_pred)}'\n",
    "logging.debug(str_)                         \n",
    "\n",
    "vec2 = [model_name,\n",
    "        str(params),\n",
    "        'TEST',\n",
    "        tn,\n",
    "        fp,\n",
    "        fn,\n",
    "        tp,\n",
    "        precision_score(y_true, y_pred,),\n",
    "        recall_score(y_true, y_pred,),\n",
    "        f1_score(y_true, y_pred,),\n",
    "        roc_auc_score(y_true=y_true, y_score=y_pred),\n",
    "        ]\n",
    "\n",
    "m = np.vstack([vec1, vec2])\n",
    "df = pd.DataFrame(m, columns=columns)\n",
    "\n",
    "if os.path.isfile(config['logreg_results']):\n",
    "    old_df = pd.read_csv(config['logreg_results'], sep=';')\n",
    "    df = pd.concat([old_df,df])\n",
    "\n",
    "# df.to_csv(config['logreg_results'], index=False, sep=';')\n",
    "logging.debug('Finishing Logistic Regression execution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419139,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
